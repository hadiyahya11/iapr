{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from typing import Callable\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.segmentation import watershed\n",
    "from scipy import ndimage\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This utility function will be used to display images in the notebook\n",
    "\n",
    "def display_image(mat, axes=None, cmap=None, hide_axis=True):\n",
    "    \"\"\"\n",
    "    Display a given matrix into Jupyter's notebook\n",
    "    \n",
    "    :param mat: Matrix to display\n",
    "    :param axes: Subplot on which to display the image\n",
    "    :param cmap: Color scheme to use\n",
    "    :param hide_axis: If `True` axis ticks will be hidden\n",
    "    :return: Matplotlib handle\n",
    "    \"\"\"\n",
    "    img = cv2.cvtColor(mat, cv2.COLOR_BGR2RGB) if mat.ndim == 3 else mat\n",
    "    cmap= cmap if mat.ndim != 2 or cmap is not None else 'gray'\n",
    "    if axes is None:\n",
    "        if hide_axis:\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "        return plt.imshow(img, cmap=cmap)\n",
    "    else:\n",
    "        if hide_axis:\n",
    "            axes.set_xticks([])\n",
    "            axes.set_yticks([])\n",
    "        return axes.imshow(img, cmap=cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function that will be used to prepare the image for coin detection\n",
    "# Preprocessing steps:\n",
    "    # 1. Resize the image to a smaller size\n",
    "    # 2. Convert the image to grayscale\n",
    "    # 3. Adjust the brightness of the image\n",
    "    # 4. Apply inRange to keep only the pixels within the bounds\n",
    "    # 5. Apply closing and opening morphological operations to remove noise\n",
    "    # 6. Return the preprocessed image\n",
    "def preprocess(image,offset=180, size_ratio=0.1,lower_bound=np.array([0, 85, 150]),upper_bound=np.array([155,205,255])):\n",
    "    image = cv2.resize(image, (int(image.shape[1]*size_ratio), int(image.shape[0]*size_ratio)), interpolation=cv2.INTER_AREA)\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    brightness = cv2.mean(gray_image)[0]\n",
    "    brightness_offset=offset-brightness\n",
    "    image_float = image.astype(np.float32)\n",
    "    image = np.clip(image_float + brightness_offset, 0, 255).astype(np.uint8)\n",
    "    # Apply inRange to keep only the pixels within the bounds\n",
    "    mask = cv2.inRange(image, lower_bound, upper_bound)\n",
    "\n",
    "    # Invert the mask to get a mask for pixels outside the bounds\n",
    "    mask_inv = cv2.bitwise_not(mask)\n",
    "\n",
    "    # Create a white image of the same size as the original image\n",
    "    white_image = np.ones_like(image) * 255\n",
    "\n",
    "    # Use the inverted mask to turn the pixels outside the bounds in the white image to white\n",
    "    white_parts = cv2.bitwise_and(white_image, white_image, mask=mask_inv)\n",
    "\n",
    "    # Use the original mask to keep the pixels within the bounds in the original image\n",
    "    colored_parts = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "    # Combine the two parts\n",
    "    result = cv2.add(white_parts, colored_parts)\n",
    "    # Define the structuring element\n",
    "    kernel1 = np.ones((1,1),np.uint8)\n",
    "\n",
    "    # Apply the opening operation\n",
    "    opened = cv2.morphologyEx(result, cv2.MORPH_OPEN, kernel1)\n",
    "\n",
    "    # Apply the closing operation\n",
    "    closed = cv2.morphologyEx(opened, cv2.MORPH_CLOSE, kernel1)\n",
    "\n",
    "    \n",
    "    kernel2 = np.ones((1,1),np.uint8)\n",
    "    final = cv2.morphologyEx(closed, cv2.MORPH_CLOSE, kernel2)\n",
    "    final = cv2.morphologyEx(final, cv2.MORPH_OPEN, kernel2)\n",
    "    return final\n",
    "\n",
    "# Function detect coins accepts an image preprocessed and detects the coins in it\n",
    "# The function uses the Hough Circle Transform to detect the coins in the image\n",
    "# The function returns the original image with the detected coins drawn on it, the number of coins detected, the centers of the detected coins, and the segmented coin images\n",
    "def detect_coins(image, init_image, param1 = 150, param2 = 15, size_ratio=0.1):\n",
    "    min_radius=int(150*size_ratio)\n",
    "    max_radius=int(400*size_ratio)\n",
    "\n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    edges = cv2.Canny(blurred, 150, 25)\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    thresh = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)\n",
    "    circles = cv2.HoughCircles(thresh, cv2.HOUGH_GRADIENT, dp=1, minDist=3*min_radius,\n",
    "                               param1=param1, param2=param2, minRadius=min_radius, maxRadius=max_radius)\n",
    "    circles_rescaled = circles/size_ratio\n",
    "    centers = []  # List to store detected centers\n",
    "    coin_images = []  # List to store segmented coin images\n",
    "    if (circles_rescaled is not None):\n",
    "        if  (len(circles_rescaled[0]) < 25):\n",
    "            number_circles = len(circles_rescaled[0])\n",
    "            circles_rescaled = np.round(circles_rescaled[0, :]).astype(\"int\")\n",
    "            for (x, y, r) in circles_rescaled:\n",
    "                # Draw circle boundary (commented out so that final segmentations of coins don't contain drawings)\n",
    "                # cv2.circle(init_image, (x, y), r, (0, 255, 0), 4)\n",
    "                # Draw square bounding box centered on coin center (commented out so that final segmentations of coins don't contain drawings)\n",
    "                x1, y1 = x - int(r), y - int(r)\n",
    "                x2, y2 = x + int(r), y + int(r)\n",
    "                #cv2.rectangle(init_image, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "                centers.append((x*10, y*10))\n",
    "\n",
    "                coin_image = init_image[y1:y2, x1:x2]\n",
    "                coin_images.append(coin_image)\n",
    "        else:\n",
    "            number_circles = 0\n",
    "    else:\n",
    "        number_circles = 0\n",
    "\n",
    "    return init_image, number_circles, centers, coin_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation of Train Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing images\n",
    "directory = './train/'\n",
    "save_directory = './image_segmentation/'\n",
    "image_subfolders =['1. neutral_bg','2. noisy_bg', '3. hand', '4. neutral_bg_outliers','5. noisy_bg_outliers', '6. hand_outliers']\n",
    "# List to store images\n",
    "images = []\n",
    "data = {}\n",
    "# Iterate over files in the directory\n",
    "i = 0\n",
    "for context in image_subfolders:\n",
    "    image_directory = os.path.join(directory, context)\n",
    "    for filename in os.listdir(image_directory):\n",
    "        if filename.endswith('.JPG'):\n",
    "            # Load image\n",
    "            image = cv2.imread(os.path.join(image_directory, filename))\n",
    "            if image is not None:\n",
    "                # Append image to list\n",
    "                images.append(image)\n",
    "                image = detect_coins(preprocess(image), init_image=image)\n",
    "                data[f\"{context}/{filename}\"] = [[int(i[0]),int(i[1])] for i in image[2]]\n",
    "                #save image\n",
    "                save_path = os.path.join(save_directory, context, filename)\n",
    "                cv2.imwrite(save_path, image[0])\n",
    "                \n",
    "                for coin in image[3]:\n",
    "                    if not coin.size == 0:  # Check if coin image is not empty\n",
    "                        coin_name = f'{filename}_coin_{i}.JPG'\n",
    "                        cv2.imwrite(os.path.join(save_directory, 'detected_coins', coin_name), coin)\n",
    "                        i += 1\n",
    "                    else:\n",
    "                        print(f\"Error: coin image for {filename} is empty\")\n",
    "            else:\n",
    "                print(f\"Error loading image: {filename}\")\n",
    "            \n",
    "# Save the marked centers to a JSON file\n",
    "json_path = \"detected_centers.json\"\n",
    "with open(json_path, \"w\") as json_file:\n",
    "    json.dump(data, json_file, indent=4)\n",
    "print(f\"Marked centers saved to {json_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation of Ref Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing images\n",
    "directory ='./ref'\n",
    "save_directory = directory+'/segmentation'\n",
    "# List to store images\n",
    "images = []\n",
    "# Iterate over files in the directory\n",
    "i = 0\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.JPG'):\n",
    "        # Load image\n",
    "        image = cv2.imread(os.path.join(directory, filename))\n",
    "        if image is not None:\n",
    "            # Append image to list\n",
    "            images.append(image)\n",
    "            image = detect_coins(preprocess(image), init_image=image)\n",
    "            #save image\n",
    "            save_path = os.path.join(save_directory, filename)\n",
    "            cv2.imwrite(save_path, image[0])\n",
    "                \n",
    "            for coin in image[3]:\n",
    "                if not coin.size == 0:  # Check if coin image is not empty\n",
    "                    coin_name = f'{filename}_coin_{i}.JPG'                   \n",
    "                    cv2.imwrite(os.path.join(save_directory, 'detected_coins', coin_name), coin)\n",
    "                    i += 1\n",
    "                else:\n",
    "                    print(f\"Error: coin image for {filename} is empty\")\n",
    "        else:\n",
    "            print(f\"Error loading image: {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation of Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: coin image for L0000103.JPG is empty\n",
      "Error: coin image for L0000140.JPG is empty\n",
      "Error: coin image for L0000045.JPG is empty\n",
      "Error: coin image for L0000095.JPG is empty\n"
     ]
    }
   ],
   "source": [
    "# Directory containing images\n",
    "directory = './test'\n",
    "save_directory = directory+'/segmentation'\n",
    "# List to store images\n",
    "images = []\n",
    "# Iterate over files in the directory\n",
    "i = 0\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.JPG'):\n",
    "        # Load image\n",
    "        image = cv2.imread(os.path.join(directory, filename))\n",
    "        if image is not None:\n",
    "            # Append image to list\n",
    "            images.append(image)\n",
    "            image = detect_coins(preprocess(image), init_image=image)\n",
    "            #save image\n",
    "            save_path = os.path.join(save_directory, filename)\n",
    "            cv2.imwrite(save_path, image[0])\n",
    "                \n",
    "            for coin in image[3]:\n",
    "                if not coin.size == 0:  # Check if coin image is not empty\n",
    "                    coin_name = f'{filename}_coin_{i}.JPG'                   \n",
    "                    cv2.imwrite(os.path.join(save_directory, 'detected_coins', coin_name), coin)\n",
    "                    i += 1\n",
    "                else:\n",
    "                    print(f\"Error: coin image for {filename} is empty\")\n",
    "        else:\n",
    "            print(f\"Error loading image: {filename}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "from PIL.Image import Resampling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torchvision.models import  ResNet50_Weights\n",
    "from torch.optim import lr_scheduler\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation and splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a custom dataset class to load the data and split it into train and validation sets. We also create a custom collate function to pad the sequences to the same length so we don't loose information when resizing when using the resnet50 model because it uses images of size 224x224.\n",
    "Since our segmentation may produce images without coins sometimes, we added a label for the background class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the class labels\n",
    "classes = [\"5CHF\", \"2CHF\", \"1CHF\", \"0.5CHF\", \"0.2CHF\", \"0.1CHF\", \"0.05CHF\", \"2EUR\", \"1EUR\", \"0.5EUR\",\n",
    "           \"0.2EUR\", \"0.1EUR\", \"0.05EUR\", \"0.02EUR\", \"0.01EUR\", \"OOD\", \"BG\"]\n",
    "\n",
    "# Custom Dataset Class\n",
    "class CoinDataset(Dataset):\n",
    "    def __init__(self, labels, img_dir, transform=None):\n",
    "        self.labels = labels\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        # Convert labels from dictionary to list of tuples\n",
    "        self.data = list(self.labels.items())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name, label = self.data[idx]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        image = Image.open(img_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, torch.tensor(classes.index(label))  # Convert label to tensor index\n",
    "\n",
    "\n",
    "class ResizeWithPad:\n",
    "    def __init__(self, target_size):\n",
    "        self.target_size = target_size\n",
    "\n",
    "    def __call__(self, image):\n",
    "        # Resize the image maintaining the aspect ratio\n",
    "        image.thumbnail(self.target_size, Resampling.LANCZOS)\n",
    "        # Create a new image with a white background\n",
    "        new_image = Image.new(\"RGB\", self.target_size, (255, 255, 255))\n",
    "        # Paste the resized image onto the new image, centered\n",
    "        new_image.paste(image, ((self.target_size[0] - image.size[0]) // 2, (self.target_size[1] - image.size[1]) // 2))\n",
    "        return new_image\n",
    "\n",
    "# Data Transformations\n",
    "transform_train = transforms.Compose([\n",
    "    ResizeWithPad((224, 224)),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.05),\n",
    "    transforms.RandomAdjustSharpness(sharpness_factor=2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "transform_val = transforms.Compose([\n",
    "    ResizeWithPad((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# Load the JSON file\n",
    "with open('./labels.json') as f:\n",
    "    labels = json.load(f)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_labels, val_labels = train_test_split(list(labels.items()), test_size=0.1, random_state=42)\n",
    "\n",
    "# Convert back to dictionaries for the Dataset class\n",
    "train_labels = dict(train_labels)\n",
    "val_labels = dict(val_labels)\n",
    "\n",
    "# Set the image directory\n",
    "img_dir = '/detected_coins/'\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = CoinDataset(labels=train_labels, img_dir=img_dir, transform=transform_train)\n",
    "val_dataset = CoinDataset(labels=val_labels, img_dir=img_dir, transform=transform_val)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_classes = len(classes)  # 15 classes + 1 for OOD + 1 for BG\n",
    "\n",
    "model = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
    "\n",
    "# Replace the last fully connected layer\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "\n",
    "# Move the model to the appropriate device (GPU or CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = './v2.pth'\n",
    "\n",
    "def train(model, train_loader, val_loader, criterion, optimizer,scheduler, num_epochs):\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        best_val_accuracy = 0.0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_accuracy = running_corrects.double() / len(train_loader.dataset)\n",
    "\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_accuracy = 100 * correct / total\n",
    "        # Save the best model\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "          best_val_accuracy = val_accuracy\n",
    "          torch.save(model.state_dict(), best_model_path)\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {train_loss*100}, Training Accuracy: {train_accuracy}, Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.01,weight_decay=1e-3)\n",
    "exp_lr_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "train(model, train_loader, val_loader, criterion, optimizer,exp_lr_scheduler, num_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = pd.read_csv('./sample_submission.csv')\n",
    "df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
    "num_classes = len(classes)\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, num_classes)\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "model.eval()\n",
    "model = model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define the transform\n",
    "transform = transforms.Compose([\n",
    "    ResizeWithPad((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(image_path, model, transform, device):\n",
    "    image = Image.open(image_path)\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "    return predicted.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = './segments_wo_bb/'\n",
    "for image_name in os.listdir(test_dir):\n",
    "  image_path = os.path.join(test_dir, image_name)\n",
    "  image_id = image_name.split('_')[0]\n",
    "  image_id = image_id[:8]\n",
    "  predicted_label = predict_image(image_path, model, transform, device)\n",
    "  #dismiss images classfied as background\n",
    "  if classes[predicted_label] != \"BG\":\n",
    "    row_idx = df_out[df_out['id'] == image_id].index[0]\n",
    "    df_out.loc[row_idx, classes[predicted_label]] += 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to csv for submission\n",
    "df_out.to_csv('sub.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
